{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "from bson.objectid import ObjectId\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = MongoClient(os.environ.get(\"MONGODB_URI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchData(client):\n",
    "  result  = client.reddit.images.metadata.find(\n",
    "      {\"category_human\": {\"$exists\": True}},\n",
    "      {\"url\":1,\"phash\":1,\"category_human\":1}\n",
    "      )\n",
    "  return result\n",
    "\n",
    "def retrieveImages(data,n):\n",
    "  tmp = data[0:n]\n",
    "  for entry in tqdm(data[0:n]):\n",
    "    image = Image.open(requests.get(entry[\"url\"], stream=True).raw)\n",
    "    entry[\"image\"]=image\n",
    "  return tmp\n",
    "\n",
    "data = list(fetchData(client))\n",
    "data=retrieveImages(data,500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"USER: <image>\\n Please categorize the image into one of the following categories: 'Reddit', 'Instagram', 'Facebook', 'Discord', 'TikTok', 'Messaging', 'News', 'Meme', 'Tweet', or 'Other'. Focus on visual and textual clues that might indicate the source platform or content type. \\nASSISTANT:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/zidane/llava/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "def llava_label(data):\n",
    "    for entry in tqdm(data):\n",
    "        outputs = pipe(entry[\"image\"], prompt=prompt, generate_kwargs={\"max_new_tokens\": 1000})\n",
    "        entry[\"category_llava\"] = outputs[0][\"generated_text\"].split(\"ASSISTANT: \")[1]\n",
    "\n",
    "llava_label(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)[['category_human', 'category_llava', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category_human category_llava                                  url\n",
      "0           Tweet       Facebook  https://i.redd.it/q49trvdqfa3a1.jpg\n",
      "1           Tweet         Reddit  https://i.redd.it/huab7xr7ed3a1.jpg\n",
      "2            Meme      Instagram  https://i.redd.it/g5picrl8ie3a1.jpg\n",
      "3           Other          Other  https://i.redd.it/gm6a3y4aif3a1.jpg\n",
      "4          Reddit         Reddit  https://i.redd.it/t8b1v46hjg3a1.jpg\n",
      "5           Tweet        Twitter  https://i.redd.it/5vbryiwc5f3a1.png\n",
      "6           Tweet      Instagram  https://i.redd.it/dmzg6wi10g3a1.jpg\n",
      "7            Meme           Meme  https://i.redd.it/o6sljqhq0i3a1.jpg\n",
      "8            Meme           Meme  https://i.redd.it/bihyeo5imh3a1.jpg\n",
      "9       Messaging         Reddit  https://i.redd.it/e12o69tm1i3a1.jpg\n",
      "10          Other          Other  https://i.redd.it/qpqlgn4p5g3a1.jpg\n",
      "11          Other          Other  https://i.redd.it/lhmgbzi1a83a1.jpg\n",
      "12           Meme           Meme  https://i.redd.it/oaf8fa75fl3a1.jpg\n",
      "13          Other          Other  https://i.redd.it/t5o9fpjq3i3a1.jpg\n",
      "14         Reddit         Reddit  https://i.redd.it/tv0luny5ll3a1.jpg\n",
      "15          Other          Tweet  https://i.redd.it/t3eoi6fv1l3a1.jpg\n",
      "16          Other          Other  https://i.redd.it/77g28cxdnn3a1.jpg\n",
      "17           Meme           Meme  https://i.redd.it/475k0d6p9m3a1.jpg\n",
      "18           Meme          Other  https://i.redd.it/oyxxuls3ym3a1.jpg\n",
      "19         TikTok         Reddit  https://i.redd.it/646dt71lgk3a1.png\n"
     ]
    }
   ],
   "source": [
    "print(df[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 42.0%\n"
     ]
    }
   ],
   "source": [
    "matches = (df['category_human'] == df['category_llava']).sum()\n",
    "print(\"Accuracy: %s%%\" % ((matches/len(data))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"output.xlsx\", index=False, engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
